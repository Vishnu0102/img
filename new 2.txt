witboost -- builder --mydataproducts
buildrer-template -dataptorduct 
owner urname
ee89
uci
email
tactical
disc.. payment vishnu 
emai wwithout @unicredit 

ghb.internalunicredit 

account settings 
htts acces token - create tocken 
witboost dev
project permisision - proket admin  inherited
copy tocken ... 

dmb.dtatamesh.dpug4c.unicredit
profile settings and advanced 
paste the tocken and save 


now create a dataprocut 
gdpr regurlation no 


builder  there dermio storage if it is a table 

dremio -
dataabses- tg6ee00-Rs1minf- copy path edeitor 
and select * from path 


gcd-storage-payemnt 

mesh_pysaprk

Pysaprk workload :
go to catlog info and choose swift rs for reference 

full housekeeping ()  source alligned data product 
-dataabsse

customer alligned --then diffeenrnt -dataproduct 

cadp 

upload code 
in bitbucket go to sprk 
upload library  and iso 


devops/ artifact then change version 
devops configurtation ,
catalog info  , orkload version , articatft version 
pyprojevct .toml 


go to git bash 
repo settings and copy the name 
go to gitbash 
git clone url 
and provide user and password 
ls
directory 


after few days if u want to see changes git pull 
cd spark app and ls 
spark-app

vi file _name  
and git statud save

jeniks -> 
build queue -

for o/p 
bit - meshsql-opcharges-swift 
pay_swiftRS 
00

schema definition 
catalog info
colum uter  varchar , no conatrint 
relevant ..
techincal -time stamp like taht 

slo 1,1 


Workload airflow 
airflow schele ..

daraproduct development team user 

dermio , pyspark , airflow , we need to do build ...





1) 


domestic cz python we can see that 
bgio
